"""DO NOT MODIFY OR RENAME THIS FILE YOURSELF.

This file consists of APIs meant to be utilized by Jupyter Notebooks for run analytics.

General usage should be to utilize the `IPSAnalysisApi` instance variable, `ips_analysis_api`, created for you in the cell the IPS Portal injects before your own cells.

For more advanced usage, you can also utilize the standalone functions provided in this module.
"""

from __future__ import annotations

import csv
import datetime
import json
import operator
import os
import tarfile
from functools import reduce
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from collections.abc import Iterable

THIS_DIR = Path(__file__).resolve().parent

IPS_DATA_LIST_FILE = 'ips_analysis_api_data_listing.json'
IPS_CHILD_RUNS_FILE = 'ips_analysis_api_child_runs.txt'


class IPSAnalysisApi:
    """This class should get used directly by notebooks directly associated with a run.

    The IPS Portal will insert a new code cell prior to your actual cells; this cell will initialize the `ips_analysis_api` object, an instance of this class.
    This object can be used in your own code to look up information about the run by calling various methods.
    None of the methods called should mutate any state.
    """

    def __init__(self, run_directory: Path):
        """This constructor is called in a cell generated by the IPS Portal, so you shouldn't have to call this yourself. Just use the `ips_analysis_api` instance variable established for you."""
        self._run_directory = run_directory

    def get_data(self) -> dict[float, list[str]]:
        """This allows you to obtain all data information associated with this run.

        Note that it is your responsibility to handle loading the actual data itself.

        :returns: a dictionary of timestep keys (as floating point values) to a list of data filepaths associated with the timestep
        """
        return _get_data_from_directory(self._run_directory)

    def get_child_data(self) -> dict[int, dict[float, list[str]]]:
        """This allows you to obtain all data information about all child runs.

        Note that it is your responsibility to handle loading the actual data itself.

        :returns: a dictionary of child runids to an additional mapping of timesteps to a list of data filepaths associated with the timestep.
        """
        child_runids = _get_children_ids_from_directory(self._run_directory)
        return get_data_from_runids(child_runids)

    def get_child_data_by_ensemble_names(
        self,
        component_names: list[str] | None = None,
        ensemble_names: list[str] | None = None,
    ) -> dict[int, dict[float, list[str]]]:
        """This allows you to obtain all data information about child runs which are also ensembles. You can use ensemble names as an additional filter.

        Note that it is your responsibility to handle loading the actual data itself.

        :param component_names: (default: None) list of components you want to search in the return data. If None, search all of them.
        :param ensemble_names: (default: None) list of ensembles you want to include in the return data. If None, return all children which are ensembles.
        :returns: a mapping of this run's child runids (associated with ensembles, and potentially filtered by the specific ensembles in the `ensemble_names` param) to an additional mapping of timesteps to a list of data filepaths associated with the timestep
        """
        child_runids = _get_children_ids_by_ensemble_names_from_directory(
            self._run_directory, component_names, ensemble_names
        )
        return get_data_from_runids(child_runids)

    def get_child_data_not_ensembles(self) -> dict[int, dict[float, list[str]]]:
        """This allows you to obtain all data information about child runs which are NOT ensembles.

        :returns: a mapping of this run's child runids (excluding those associated with ensembles) to an additional mapping of timesteps to a list of data filepaths associated with the timestep
        """
        child_runids = _get_nonensemble_child_ids_by_directory(self._run_directory)
        return get_data_from_runids(child_runids)


### FUNCTIONS - these can be used if making custom multi-run notebooks or if using the provided ips_analysis_api Jupyter notebook ###


def _normalize_data_filepaths(base_dir: Path, data: dict[str, list[str]]) -> dict[float, list[str]]:
    """INTERNAL USE ONLY

    Normalizes the data in the following ways:

    - Make sure the Python dictionary uses floating point keys (since JSON requires keys to be strings), and that the keys are in ascending order
    - Make sure all path strings in "data" are absolute paths instead of relative paths.
    """
    new_dict: dict[float, list[str]] = {}
    for str_timestep, file_path_list in data.items():
        timestep = float(str_timestep)
        new_dict[timestep] = file_path_list
        for idx, file_path in enumerate(file_path_list):
            new_dict[timestep][idx] = str(base_dir / Path(file_path))
    return {key: new_dict[key] for key in sorted(new_dict.keys())}


def _get_data_from_directory(directory: Path) -> dict[float, list[str]]:
    """INTERNAL USE ONLY

    'directory' should be an absolute path, not a relative path."""
    with open(directory / IPS_DATA_LIST_FILE, 'rb') as f:
        data: dict[str, list[str]] = json.load(f)
    return _normalize_data_filepaths(directory, data)


def get_data_from_runid(runid: int) -> dict[float, list[str]]:
    """Load all data associated with a single runid into a dictionary.

    Params:
      - runid: the run id we're working with

    Returns:
      - a dictionary mapping timesteps to associated data file paths.
    """
    return _get_data_from_directory(THIS_DIR / str(runid))


def get_data_from_runids(runids: Iterable[int]) -> dict[int, dict[float, list[str]]]:
    """Load all data associated with multiple runids into a common data structure.

    :param runids: iterable of existing runids (note that it is the caller's responsibility to verify uniqueness)
    :returns: a dictionary of runids to the common runid data structure. This data structure is a mapping of timesteps to associated data file paths.
    """
    return {runid: get_data_from_runid(runid) for runid in runids}


def _get_children_ids_from_directory(directory: Path) -> list[int]:
    """INTERNAL USE ONLY."""
    with open(directory / IPS_CHILD_RUNS_FILE) as f:
        raw_data = f.read()
    return sorted(int(runid) for runid in raw_data.split())


def get_children_ids_by_parent_id(parent_runid: int) -> list[int]:
    """Get the runids of all child runs of the parent.

    :param parent_runid: the ID of the parent we want the children of
    :returns: all child runids
    """
    return _get_children_ids_from_directory(THIS_DIR / str(parent_runid))


def get_children_ids_not_ensembles(parent_runid: int) -> set[int]:
    """Get the runids of all child runs of the parent which are NOT associated with an ensemble.

    :param parent_runid: the ID of the parent we want the children of
    :returns: child runids not associated with any ensemble
    """
    return _get_nonensemble_child_ids_by_directory(THIS_DIR / str(parent_runid))


def _get_nonensemble_child_ids_by_directory(parent_runid_directory: Path) -> set[int]:
    """INTERNAL USE ONLY."""
    all_ids = set(_get_children_ids_from_directory(parent_runid_directory))
    ensemble_ids = _get_children_ids_by_ensemble_names_from_directory(parent_runid_directory)
    return all_ids.difference(ensemble_ids)


def get_children_ids_by_ensemble_names_of_parent(
    parent_runid: int,
    component_names: list[str] | None = None,
    ensemble_names: list[str] | None = None,
) -> set[int]:
    """Get the runids of all child runs of the parent which are associated with 'component_names' and 'ensemble_names'.

    Note that this function always returns at least one child associated with an ensemble, and only returns children associated with an ensemble.

    :param parent_runid: the ID of the parent we want the children of
    :param component_names: (default: None) list of components you want to search for the return data. If None, search all components.
    :param ensemble_names: (default: None) list of ensembles you want to include in the return data. If None, return all children which are ensembles.
    :returns: child runids associated with the listed ensembles (or all ensembles if ensemble_names param was not provided)
    """
    return _get_children_ids_by_ensemble_names_from_directory(
        THIS_DIR / str(parent_runid), component_names, ensemble_names
    )


def _get_children_ids_by_ensemble_names_from_directory(
    parent_runid_directory: Path,
    component_names: list[str] | None = None,
    ensemble_names: list[str] | None = None,
) -> set[int]:
    """INTERNAL USE ONLY."""
    ENSEMBLES_DIRECTORY = parent_runid_directory / 'ensembles'

    if component_names:
        ensemble_paths = reduce(
            operator.iconcat,
            [(ENSEMBLES_DIRECTORY / component_name).glob('*.csv') for component_name in component_names],
            [],
        )
    else:
        ensemble_paths = list(ENSEMBLES_DIRECTORY.rglob('**/*.csv'))
    # TODO - what if we want to search for specific ensemble names only in specific components? may need to change the API to handle this.
    if ensemble_names:
        ensemble_paths = list(filter(lambda p: p.name[:-4] in ensemble_names, ensemble_paths))

    child_runids = set()
    for epath in ensemble_paths:
        with open(epath) as fd:
            rows = csv.DictReader(fd)
            for row in rows:
                child_runids.add(int(row['portal_runid']))
    return child_runids


def generate_tar_from_runids(runids: Iterable[int] | int) -> str:
    """
    Generate a tarball containing all data from the provided runs

    :param runids: list of runids where we want to include the data
    :returns: the absolute path of the tarball generated
    """
    tarball_name = (
        f'{datetime.datetime.now(datetime.timezone.utc).isoformat().replace(":", "-").replace("+", "_")}__ips_runs'
    )
    tarball = THIS_DIR / f'{tarball_name}.tar.gz'
    with tarfile.open(tarball, 'w:gz') as archive:
        # add API files inside the tarball
        for api_file in THIS_DIR.glob('ips_analysis_api_v*'):
            if api_file.suffix in ('.py', '.ipynb'):
                arcname = os.path.join(tarball_name, api_file.name)
                archive.add(api_file, arcname=arcname)

        if isinstance(runids, int):
            runids = [runids]

        # add runids in directory
        for runid in runids:
            arcname = os.path.join(tarball_name, str(runid))
            archive.add(os.path.join(THIS_DIR, str(runid)), arcname=arcname)

    return str(tarball)
